{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "481d5e28-ab28-49b8-89b9-2fc7ecf8a4fd",
   "metadata": {},
   "source": [
    "# 03c - Record File Tree Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bac9b7a6-8ff9-4d5d-9a04-57e9484a3b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install --upgrade pip -q\n",
    "!{sys.executable} -m pip install pandas -q\n",
    "!{sys.executable}  -m pip install numpy -q\n",
    "!{sys.executable}  -m pip install matplotlib -q\n",
    "!{sys.executable}   -m pip install scipy -q\n",
    "!{sys.executable}   -m pip install pyvis -q\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b553bd-274c-4f5d-9808-52a79f2f209d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd1ade9b-29f8-4895-85e2-c6d21c8ef0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "from collections import OrderedDict\n",
    "import psutil\n",
    "import gc\n",
    "from bisect import bisect\n",
    "from scipy import spatial\n",
    "from matplotlib.pyplot import figure\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mplt\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "from pyvis.network import Network\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import matplotlib.cm as cm\n",
    "import resource\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad8a0bc4-3614-4e47-bc04-785ef0f59e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_txt(msg: str):\n",
    "    print(msg, end = '\\r')\n",
    "    text_file = open(\"Outputs/Lvl_Tree_Rep.txt\", \"w\")\n",
    "    text_file.write(msg)\n",
    "    text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80d3377a-d689-4312-b841-a4de389aa992",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### parameter settings #######\n",
    "recreate_nodes = True\n",
    "subset = False\n",
    "plot_clusterdist = False\n",
    "node_threshold = 50\n",
    "edge_threshold = 10\n",
    "edge_prob_threshold = 0.01\n",
    "prob_threshold = 0.05\n",
    "max_numclust = 20\n",
    "tw = 120 #timewindow\n",
    "threshold_plot = False\n",
    "elo = 'high'\n",
    "\n",
    "time_list = [t for t in range(0,5001,tw)]\n",
    "time_list_long = [t for t in range(0,15000,tw)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e905e5-ee41-4d6a-827d-c694f2e01a4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2ec2d37-18eb-4536-97b5-61eed775eb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "##directorys\n",
    "input_path = 'data/scraped_matches/inputs/'\n",
    "gaia_path = 'data/scraped_matches/gaia_data/'\n",
    "viz_path = 'Visualizations/Tree_Rep/'\n",
    "\n",
    "#players\n",
    "player_ids = ['p1','p2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b437e94-1e25-4d90-bce3-4de49b2dbf09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'low': {'lb': 0, 'ub': 1062, 'label': 'Low Elo'},\n",
       " 'medium': {'lb': 1062, 'ub': 1501, 'label': 'Medium Elo'},\n",
       " 'high': {'lb': 1501, 'ub': 3000, 'label': 'High Elo'}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load masterdata\n",
    "with open('masterdata/masterdata_dict.pkl', 'rb') as f:\n",
    "        masterdata_dict = pickle.load(f)\n",
    "\n",
    "with open('masterdata/unit_type_dict.pkl', 'rb') as f:\n",
    "        unit_type_dict = pickle.load(f)        \n",
    "\n",
    "with open('masterdata/unit_masterdata_dict.pkl', 'rb') as f:\n",
    "        unit_masterdata_dict = pickle.load(f)        \n",
    "\n",
    "#load masterdata\n",
    "with open('masterdata/elo_frames.pkl', 'rb') as f:\n",
    "        elo_frames = pickle.load(f)\n",
    "elo_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2086809-c9c9-4597-be24-b48aa04ec26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eloFrame(elo,elo_frames):\n",
    "    for elo_key in elo_frames:\n",
    "        if elo >= elo_frames[elo_key]['lb'] and elo < elo_frames[elo_key]['ub']:\n",
    "            return elo_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2abf42ea-c6b6-47f3-800d-810e53ecb484",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "with open('data/scraped_matches/parsed_matches/arabia_matches.pkl', 'rb') as f:\n",
    "    org_matches = pickle.load(f)\n",
    "\n",
    "    \n",
    "for match_id in org_matches:\n",
    "    org_matches[match_id]['avg_elo'] = int((org_matches[match_id]['p1_elo']+org_matches[match_id]['p2_elo'])/2)\n",
    "    org_matches[match_id]['elo'] = get_eloFrame(org_matches[match_id]['avg_elo'],elo_frames)\n",
    "\n",
    "    \n",
    "matches = org_matches    \n",
    "if subset:\n",
    "    matches = {}\n",
    "    for key in org_matches:\n",
    "        matches[key] = org_matches[key]\n",
    "        if len(matches) >= 10000:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9108d3d7-e696-40e2-bb5e-e6ac5bd998ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Villager\n",
      "Monk\n",
      "Trade Cart\n",
      "Infantry\n",
      "Foot Archer unit\n",
      "Cavalry\n",
      "Siege unit\n",
      "Gunpowder\n",
      "Ship\n",
      "Mounted Archer\n"
     ]
    }
   ],
   "source": [
    "simple = True\n",
    "military_comp = True\n",
    "\n",
    "### 3-D Tree Vills, Military, Epoch\n",
    "global tree_dims \n",
    "\n",
    "key_types = ['Build','Queue','Research']\n",
    "#rel_items = ['Villager', 'Loom', 'Build', 'Queue', 'Research']\n",
    "id_prefix = 'ID'\n",
    "\n",
    "########################complex setting########################\n",
    "tree_dims = ['Age'] #[\"Villager\",\"Military\",\"Research\"]\n",
    "#load tree_dims from masterdata\n",
    "for key_type in key_types:\n",
    "    for sub_type in masterdata_dict[key_type]:\n",
    "        tree_dims.append(sub_type)\n",
    "########################simple setting########################\n",
    "#overwriting complex\n",
    "if simple:\n",
    "    tree_dims = ['tf','Age',\"Villager\",\"Military\",\"Build\",\"Research\"]\n",
    "\n",
    "    \n",
    "########################military composition setting########################\n",
    "if military_comp:\n",
    "    tree_dims = ['Age']\n",
    "    for type in unit_type_dict:\n",
    "        print(type)\n",
    "        tree_dims.append(type)\n",
    "    \n",
    "#############################################################################    \n",
    "    \n",
    "def get_node_id(state: dict):\n",
    "    \"\"\"get a node id string from a given game state dict\"\"\"\n",
    "    id = id_prefix\n",
    "    for dim in tree_dims:\n",
    "        if state[dim] > 0:\n",
    "            id += f'_{dim}_{state[dim]}'\n",
    "    return id\n",
    "\n",
    "def get_node_state(id: str):\n",
    "    \"\"\"get a node game state from a given node id string\"\"\"\n",
    "    \n",
    "    state = {}\n",
    "    \n",
    "    id = id[len(id_prefix):]\n",
    "    state_list = id.split(\"_\")[1:]\n",
    "    \n",
    "    while len(state_list)>0:\n",
    "        #read vals in dict\n",
    "        dim = state_list[0]\n",
    "        val = state_list[1]\n",
    "        state[dim] = int(val)\n",
    "        #update statelist\n",
    "        state_list = state_list[2:]\n",
    "        \n",
    "    for dim in tree_dims:\n",
    "        if dim not in state:\n",
    "            state[dim] = 0\n",
    "    \n",
    "    return state\n",
    "\n",
    "\n",
    "\n",
    "class TreeNode:\n",
    "    \"\"\"3D Tree Node Class with Dimensions Villiagers, Military Units and Epoch\"\"\"\n",
    "    \n",
    "    def __init__(self, id):\n",
    "        \n",
    "        self.id = id\n",
    "        \n",
    "        #win/loss stat\n",
    "        self.visits = 0\n",
    "        self.win = 0\n",
    "        self.loss = 0\n",
    "        \n",
    "        self.elos = {}\n",
    "        for elo_key in elo_frames:\n",
    "            self.elos[elo_key] = 0\n",
    "        \n",
    "        #get node state from function\n",
    "        self.state = get_node_state(self.id)\n",
    "        \n",
    "        #add up all items from state\n",
    "        self.age = self.state['Age']\n",
    "        #self.tf = self.state['tf']\n",
    "        self.level = 0\n",
    "        for item in self.state:\n",
    "            self.level += self.state[item]\n",
    "            \n",
    "        #create vector without tf info\n",
    "        self.state_vector = [self.level]\n",
    "        for dim in tree_dims[1:]:\n",
    "            if dim in self.state:\n",
    "                self.state_vector.append(self.state[dim])\n",
    "            else:\n",
    "                self.state_vector.append(0)\n",
    "        \n",
    "        \n",
    "        #incomming and outcomming edges\n",
    "        self.in_edges = {}\n",
    "        self.out_edges = {}\n",
    "        \n",
    "        self.in_nodes = []\n",
    "        self.out_nodes = []\n",
    "        \n",
    "        #init cluster allocation\n",
    "        self.cluster_id = \"init\"\n",
    "        \n",
    "    def update_stats(self):\n",
    "        self.visits = self.win + self.loss\n",
    "        self.winrate = self.win/self.visits\n",
    "        \n",
    "def use_edge(out_node: TreeNode,in_node: TreeNode, bol_win: bool,elo):\n",
    "    \"\"\"update the edge values for the transition from one game state value to another\"\"\"\n",
    "    \n",
    "    #add values\n",
    "    if bol_win:\n",
    "        in_node.win +=1\n",
    "    else:\n",
    "        in_node.loss +=1\n",
    "        \n",
    "    #update elo\n",
    "    in_node.elos[elo] +=1\n",
    "    \n",
    "    #add edge or edgecount for out and in node\n",
    "    if in_node.id in out_node.out_edges:\n",
    "        out_node.out_edges[in_node.id] += 1\n",
    "    else:\n",
    "        out_node.out_edges[in_node.id] = 1\n",
    "        \n",
    "    if out_node.id in in_node.in_edges:\n",
    "        in_node.in_edges[out_node.id] += 1\n",
    "    else:\n",
    "         in_node.in_edges[out_node.id] = 1\n",
    "    \n",
    "    #add to in_node/out_nodes list\n",
    "    out_node.out_nodes.append(in_node)\n",
    "    in_node.in_nodes.append(out_node)\n",
    "            \n",
    "    #update stats\n",
    "    in_node.update_stats()\n",
    "\n",
    "def get_distance(node1: TreeNode, node2: TreeNode):\n",
    "    \"\"\"return cosine similarity between 2 TreeNodes\"\"\"\n",
    "    dist = (spatial.distance.cosine(node1.state_vector,node2.state_vector))\n",
    "    return dist\n",
    "    \n",
    "    \n",
    "class TreeNodeCluster:\n",
    "    def __init__(self,idx,level, nodes: list):\n",
    "        self.idx = idx\n",
    "        self.id = \"init\"\n",
    "        self.level = level\n",
    "        \n",
    "        \n",
    "        self.nodes = nodes\n",
    "        self.size = len(nodes)\n",
    "    \n",
    "        \n",
    "        self.state_keys = []\n",
    "        \n",
    "        #lower and upper bounds\n",
    "        self.state_lbs = {}\n",
    "        self.state_ubs = {}\n",
    "        self.state_avgs = {}\n",
    "        self.level_ub = 0\n",
    "        \n",
    "        #win/loss stat\n",
    "        self.visits = 0\n",
    "        self.win = 0\n",
    "        self.loss = 0\n",
    "        self.winrate = 0\n",
    "        \n",
    "        #intra distance\n",
    "        self.avg_intra_dist = 0\n",
    "        \n",
    "        self.label = \"init\"\n",
    "        self.dominant_key = \"init\"\n",
    "        self.update_stats()\n",
    "        \n",
    "        #edges\n",
    "        self.in_edges = {}\n",
    "        self.out_edges = {}\n",
    "        \n",
    "        #allocate nodes to cluster\n",
    "        for node in self.nodes:\n",
    "            node.cluster_id = self.id\n",
    "        \n",
    "        \n",
    "        \n",
    "    def update_stats(self):\n",
    "        \n",
    "        #reset vals\n",
    "        self.visits = 0\n",
    "        self.win = 0\n",
    "        self.loss = 0\n",
    "        max_state_val = 0\n",
    "        \n",
    "        #loop over nodes \n",
    "        for node in self.nodes:\n",
    "            self.visits += node.visits\n",
    "            self.win += node.win\n",
    "            self.loss += node.loss\n",
    "            self.winrate = self.win/self.visits\n",
    "            \n",
    "            for state_key in node.state:\n",
    "                try:\n",
    "                    #check if state is already there\n",
    "                    if state_key not in self.state_keys:\n",
    "                        self.state_keys.append(state_key)\n",
    "                        self.state_lbs[state_key] = node.state[state_key]\n",
    "                        self.state_ubs[state_key] = node.state[state_key]\n",
    "                        self.state_avgs[state_key] = node.state[state_key] * node.visits\n",
    "                        \n",
    "                    else:\n",
    "                        if self.state_lbs[state_key] > node.state[state_key]:\n",
    "                                self.state_lbs[state_key] = node.state[state_key]\n",
    "                        if self.state_ubs[state_key] < node.state[state_key]:\n",
    "                                self.state_ubs[state_key] = node.state[state_key]\n",
    "                        \n",
    "                        #add state info\n",
    "                        self.state_avgs[state_key] += node.state[state_key] * node.visits            \n",
    "                                \n",
    "                except:\n",
    "                    print(\"error:\",self.state_lbs[state_key],node.state[state_key])\n",
    "                \n",
    "                #update level\n",
    "                self.level_ub += self.state_ubs[state_key]\n",
    "                            \n",
    "        #find dominant key\n",
    "        for state_key in self.state_keys:\n",
    "            if state_key != 'tf':\n",
    "                self.state_avgs[state_key] = round(self.state_avgs[state_key] / self.visits,2)\n",
    "                if self.state_avgs[state_key] > max_state_val:\n",
    "                    max_state_val = self.state_avgs[state_key] #\n",
    "                    self.dominant_key = state_key\n",
    "        \n",
    "        #create label\n",
    "        self.label = \"ID\"\n",
    "        if self.dominant_key != \"init\":\n",
    "            self.label += \"_\" + self.dominant_key\n",
    "        for state_key in self.state_keys:\n",
    "            if self.state_ubs[state_key] > 0:\n",
    "                if self.state_lbs[state_key] == self.state_ubs[state_key]:\n",
    "                     self.label += f'_{state_key}_{self.state_lbs[state_key]}'\n",
    "                else:\n",
    "                    self.label += f'_{state_key}_{self.state_lbs[state_key]}-{self.state_ubs[state_key]}-(AVG: {self.state_avgs[state_key]})'\n",
    "        \n",
    "        \n",
    "        #loop over nodes \n",
    "        total_dist = 0\n",
    "        c = 0\n",
    "        for node1 in self.nodes:\n",
    "            for node2 in self.nodes:\n",
    "                total_dist += get_distance(node1,node2)\n",
    "                if node1 != node2:\n",
    "                    c += 1\n",
    "        if c != 0:\n",
    "            self.avg_intra_dist = total_dist/c\n",
    "        \n",
    "        #finalize values\n",
    "        self.id = self.label\n",
    "        \n",
    "\n",
    "        \n",
    "    def get_cluster_edges(self):\n",
    "        for intern_node in self.nodes:\n",
    "            #in edges\n",
    "            for extern_node in intern_node.in_nodes:\n",
    "                if extern_node.cluster_id == \"init\":\n",
    "                    pass\n",
    "                else:\n",
    "                    if extern_node.cluster_id not in self.in_edges:\n",
    "                        self.in_edges[extern_node.cluster_id] = 1\n",
    "                    else:\n",
    "                        self.in_edges[extern_node.cluster_id] += 1\n",
    "            \n",
    "            #out_edges\n",
    "            for extern_node in intern_node.out_nodes:\n",
    "                if extern_node.cluster_id == \"init\":\n",
    "                    pass\n",
    "                else:\n",
    "                    if extern_node.cluster_id not in self.out_edges:\n",
    "                        self.out_edges[extern_node.cluster_id] = 1\n",
    "                    else:\n",
    "                        self.out_edges[extern_node.cluster_id] += 1\n",
    "\n",
    "                    \n",
    "def norm_vectors(vectorset: list):\n",
    "    \"\"\" Normalize vecotors in a list of vectors\"\"\"\n",
    "    for idx,vector in enumerate(vectorset):\n",
    "        vectorset[idx].append(1)\n",
    "        \n",
    "    \n",
    "    #create empty max vector\n",
    "    max_vector = [0 for e in vectorset[0]]\n",
    "\n",
    "    for vector in vectorset:\n",
    "        for idx,val in enumerate(vector):\n",
    "            if val > max_vector[idx]:\n",
    "                max_vector[idx] = val\n",
    "                \n",
    "    normed_vectorset = vectorset\n",
    "    \n",
    "    for vec_idx,vector in enumerate(vectorset):\n",
    "        for val_idx,val in enumerate(vector):\n",
    "            if max_vector[val_idx] != 0:\n",
    "                normed_vectorset[vec_idx][val_idx] = round(val / max_vector[val_idx],10)\n",
    "    \n",
    "    return normed_vectorset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd663e38-c7e9-45ad-8dcb-cd065ddf72e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match 138000/138902 - Nodes: 3561644 -Memory: 36.1 %\r"
     ]
    },
    {
     "ename": "RecursionError",
     "evalue": "maximum recursion depth exceeded while pickling an object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRecursionError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    169\u001b[0m     sys\u001b[38;5;241m.\u001b[39msetrecursionlimit(max_rec)\n\u001b[1;32m    170\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/lvl_nodes.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m , \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 171\u001b[0m     \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m     output\u001b[38;5;241m.\u001b[39mclose() \n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mRecursionError\u001b[0m: maximum recursion depth exceeded while pickling an object"
     ]
    }
   ],
   "source": [
    "#create root node from empty gamestate\n",
    "level_step = 5\n",
    "\n",
    "init_state = {}\n",
    "for dim in tree_dims:\n",
    "    init_state[dim] = 0\n",
    "\n",
    "if recreate_nodes:\n",
    "    #create nodedict\n",
    "    nodes = {}\n",
    "\n",
    "    root_node_id = get_node_id(init_state)\n",
    "    nodes[root_node_id] = TreeNode(root_node_id)\n",
    "\n",
    "    #collect stats\n",
    "    stat_list = []\n",
    "\n",
    "\n",
    "    ############LOOP#####################\n",
    "\n",
    "\n",
    "    for index,match_id in enumerate(matches):\n",
    "        #determine winner and elo of each match\n",
    "        winner = player_ids[matches[match_id]['winner']]\n",
    "        elo = matches[match_id]['elo']\n",
    "        #open inputs\n",
    "        with open(matches[match_id]['input_fn'], 'rb') as f:\n",
    "                    inputs = pickle.load(f)\n",
    "\n",
    "\n",
    "        #only get inputs from active player\n",
    "        for p_id in player_ids:\n",
    "            #reset timeslot, init timeframes\n",
    "            #tf = 0\n",
    "            levelframes = OrderedDict()\n",
    "            level = 0\n",
    "            level_ub = 0\n",
    "            levelframes[level_ub] = []\n",
    "\n",
    "            #initialize new session for every player\n",
    "            state = {}\n",
    "            state['level'] = 0\n",
    "            \n",
    "            for dim in tree_dims:\n",
    "                state[dim] = 0\n",
    "                \n",
    "            if p_id == winner:\n",
    "                win = True\n",
    "            else:\n",
    "                win = False\n",
    "\n",
    "            \n",
    "            \n",
    "            #visit root node\n",
    "            if win:\n",
    "                nodes[root_node_id].win += 1\n",
    "            else:\n",
    "                nodes[root_node_id].loss += 1\n",
    "            \n",
    "            nodes[root_node_id].elos[elo] +=1    \n",
    "                \n",
    "            nodes[root_node_id].update_stats()\n",
    "            curr_node = nodes[root_node_id]\n",
    "\n",
    "            #sort inputs into timeframe slices\n",
    "            for input_id in inputs:\n",
    "                if inputs[input_id]['player'] == p_id:\n",
    "                    if level < level_ub:\n",
    "                        levelframes[level_ub].append(input_id)\n",
    "                        level += 1\n",
    "                    else:\n",
    "                        #create new levelframe\n",
    "                        level_ub += level_step\n",
    "                        levelframes[level_ub]= []\n",
    "                        levelframes[level_ub].append(input_id)\n",
    "                        level \n",
    "\n",
    "            for level_ub in levelframes:\n",
    "                #update tf\n",
    "                state['level'] = level_ub\n",
    "\n",
    "                for input_id in levelframes[level_ub]:\n",
    "                    input = inputs[input_id]\n",
    "\n",
    "                    if input['type'] in key_types:\n",
    "                    #only select from key type\n",
    "\n",
    "                    ##STATE UPDATE after Input ######################\n",
    "                        ########################complex setting########################\n",
    "                        if not simple:\n",
    "                            if input['param'] in masterdata_dict['Ages']:\n",
    "                                #handle ages\n",
    "                                state['Age'] = masterdata_dict['Ages'].index(input['param']) + 1\n",
    "                            else:\n",
    "                            #all other intputs    \n",
    "                                if input['param'] in state:\n",
    "                                    state[input['param']] += 1\n",
    "                                else:\n",
    "                                    state[input['param']] = 1\n",
    "\n",
    "\n",
    "                        ########################military comp setting########################        \n",
    "                        elif military_comp:\n",
    "                            if input['param'] != 'None' and input['param'] != 'Villager':\n",
    "                                #handle ages\n",
    "                                if input['param'] in masterdata_dict['Ages']:  \n",
    "                                    state['Age'] = masterdata_dict['Ages'].index(input['param']) + 1\n",
    "                                #handles military and vills\n",
    "                                if input['type'] == 'Queue':\n",
    "                                    state[unit_masterdata_dict[input['param']]['Type']] += 1\n",
    "                        ########################simple setting########################        \n",
    "                        else:\n",
    "                            #handle ages\n",
    "                            if input['param'] in masterdata_dict['Ages']:  \n",
    "                                state['Age'] = masterdata_dict['Ages'].index(input['param']) + 1\n",
    "\n",
    "                            elif input['type'] == 'Research':\n",
    "                                state['Research'] += 1\n",
    "\n",
    "                            elif input['type'] == 'Build':\n",
    "                                state['Build'] += 1\n",
    "\n",
    "                            #handles military and vills\n",
    "                            elif input['type'] == 'Queue':\n",
    "                                if input['param'] == 'Villager':\n",
    "                                    state['Villager'] +=1\n",
    "                                else:\n",
    "                                    state['Military'] +=1\n",
    "\n",
    "                        ################################################################## \n",
    "\n",
    "\n",
    "\n",
    "                ############################## NODE UPDATE after TF ############################\n",
    "                ## get target node id\n",
    "                next_node_id = get_node_id(state)\n",
    "\n",
    "                #check for double click ups\n",
    "                if not curr_node.id == next_node_id:\n",
    "\n",
    "                    ##check if node exists, if not create it\n",
    "                    if next_node_id not in nodes:\n",
    "                        nodes[next_node_id] = TreeNode(next_node_id)\n",
    "\n",
    "                    ##use edge and visit node\n",
    "                    use_edge(curr_node,nodes[next_node_id], win, elo)\n",
    "\n",
    "\n",
    "                    ##update current node\n",
    "                    curr_node = nodes[next_node_id]\n",
    "\n",
    "        #log and delete\n",
    "        if index % 1000==0:\n",
    "            print_txt(f'Match {index}/{len(matches)} - Nodes: {len(nodes)} -Memory: {str(psutil.virtual_memory()[2])} %')\n",
    "            stat_list.append(len(nodes))\n",
    "            gc.collect()\n",
    "    \n",
    "    \n",
    "    #delete with threshold 10\n",
    "    del_list = []\n",
    "    for node_id in nodes:\n",
    "        if nodes[node_id].visits < 10:\n",
    "            del_list.append(node_id)\n",
    "    \n",
    "    for node_id in del_list:\n",
    "        del nodes[node_id]\n",
    "    \n",
    "    #persistate\n",
    "    max_rec = 0x1000000\n",
    "    resource.setrlimit(resource.RLIMIT_STACK, [0x100 * max_rec, resource.RLIM_INFINITY])\n",
    "    sys.setrecursionlimit(max_rec)\n",
    "    output = open('data/lvl_nodes.pkl' , 'wb')\n",
    "    pickle.dump(nodes, output)\n",
    "    output.close() \n",
    "    \n",
    "else:\n",
    "    root_node_id = get_node_id(init_state)\n",
    "    with open('data/lvl_nodes.pkl', 'rb') as f:\n",
    "        nodes = pickle.load(f)\n",
    "    print(f'{len(nodes)} Nodes loaded from pkl')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbee445-8345-43c4-80c8-e03e1c31c05a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cceb4023-b5d5-4b75-b524-6d74e088658d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    figure(figsize=(10, 10), dpi=50)\n",
    "    x_axis = [ 1000 * i for i in range(int(len(matches)/1000))]\n",
    "    ax = plt.gca()\n",
    "    ax.tick_params(axis='y', which='major', labelsize=5)\n",
    "    ax.set_xlim([0, len(matches)])\n",
    "    plt.plot(x_axis,stat_list)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b49baec-b219-44cc-be8f-4b5e33aede93",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if threshold_plot:\n",
    "    x_th = []\n",
    "    y_th = []\n",
    "    threshold = 0\n",
    "    last_len = 51\n",
    "\n",
    "    while last_len > 50 and threshold < 200:\n",
    "\n",
    "        rel_nodes = []\n",
    "        rel_node_ids = []\n",
    "\n",
    "        for node_id in nodes:\n",
    "            #node.state_vector.pop(0)\n",
    "            curr_node = nodes[node_id]\n",
    "            if curr_node.visits >= threshold:# or curr_node.winrate > 0.6 and curr_node.winrate < 0.99 and curr_node.visits >= 10: \n",
    "                rel_nodes.append(curr_node)\n",
    "                rel_node_ids.append(node_id)\n",
    "                #print(curr_node.visits, \"-\", curr_node.winrate,\"-\",curr_node.id)\n",
    "\n",
    "        x_th.append(threshold)\n",
    "        y_th.append(len(rel_nodes))\n",
    "\n",
    "        if threshold > 500:\n",
    "            threshold += 10\n",
    "        else:\n",
    "            threshold += 1\n",
    "        last_len = len(rel_nodes)\n",
    "        print_txt(f'Threshold: {threshold} - Len: {last_len}                           ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff94450-6bca-4448-b7ca-706f4847bc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "if threshold_plot:\n",
    "    from matplotlib.ticker import (MultipleLocator, AutoMinorLocator)\n",
    "    figure(figsize=(6, 6))\n",
    "    ax = plt.gca()\n",
    "    ax.tick_params(axis='y', which='major', labelsize=14)\n",
    "    ax.tick_params(axis='x', which='major', labelsize=14)\n",
    "    ax.set_xlim([0, x[-1]])\n",
    "    ax.set_ylim([0, 20000])\n",
    "    ax.xaxis.set_minor_locator(AutoMinorLocator())\n",
    "    ax.yaxis.set_minor_locator(AutoMinorLocator())\n",
    "    ax.tick_params(which='minor', length=10, color='grey')\n",
    "    #plt.title('Remaining Nodes per Threshold',fontsize=14)\n",
    "    plt.xlabel(\"Set Threshold\",fontsize=14)\n",
    "    plt.ylabel(\"Remaining Nodes\",fontsize=14)\n",
    "    plt.plot(x_th,y_th)\n",
    "    plt.grid(which = 'major',color='lightgrey', linestyle='-', linewidth=2)\n",
    "    plt.savefig(viz_path + 'nodes_per_th')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7c5a18-0f05-488a-90a0-3db47d456dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_nodes = []\n",
    "rel_node_ids = []\n",
    "\n",
    "for node_id in nodes:\n",
    "    #node.state_vector.pop(0)\n",
    "    curr_node = nodes[node_id]\n",
    "    if curr_node.visits >= node_threshold:# or curr_node.winrate > 0.6 and curr_node.winrate < 0.99 and curr_node.visits >= 10: \n",
    "        rel_nodes.append(curr_node)\n",
    "        rel_node_ids.append(node_id)\n",
    "        #print(curr_node.visits, \"-\", curr_node.winrate,\"-\",curr_node.id)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76396cfd-2e1f-4968-bd8d-9023dc8b6c1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nprint(len(nodes),len(rel_nodes))\\n#rel_nodes = rel_nodes[:1000]\\ntf_node_dict = {}\\ntf_rel_node_dict = {}\\n\\nfor tf in time_list:\\n    tf_node_dict[tf] = 0\\n    tf_rel_node_dict[tf] = 0\\n    \\nfor node_id in nodes:\\n    node_tf = nodes[node_id].tf\\n    if node_tf <= 5000:\\n        tf_node_dict[node_tf] +=1\\n    \\nfor node_id in rel_node_ids:\\n    tf_rel_node_dict[nodes[node_id].tf] +=1\\n    \\ntf_node_df = pd.DataFrame.from_dict(tf_node_dict,orient='index')\\ntf_rel_node_df = pd.DataFrame.from_dict(tf_rel_node_dict,orient='index')\\n\\nfig,ax1 = plt.subplots()\\nax1.plot(tf_node_df)\\nax2 = ax1.twinx()\\nax2.plot(tf_rel_node_df.iloc[:2000],color='orange')\\nplt.xticks(range(0,5000,500))\\nplt.axvline(1320, linestyle='dashed', linewidth=1,color='tab:orange')\\n\\nax1.grid()\\nax1.margins(x=0.00,y=0)\\nax2.margins(x=0.00,y=0)\\nplt.tight_layout()\\nplt.show()\\n\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "print(len(nodes),len(rel_nodes))\n",
    "#rel_nodes = rel_nodes[:1000]\n",
    "tf_node_dict = {}\n",
    "tf_rel_node_dict = {}\n",
    "\n",
    "for tf in time_list:\n",
    "    tf_node_dict[tf] = 0\n",
    "    tf_rel_node_dict[tf] = 0\n",
    "    \n",
    "for node_id in nodes:\n",
    "    node_tf = nodes[node_id].tf\n",
    "    if node_tf <= 5000:\n",
    "        tf_node_dict[node_tf] +=1\n",
    "    \n",
    "for node_id in rel_node_ids:\n",
    "    tf_rel_node_dict[nodes[node_id].tf] +=1\n",
    "    \n",
    "tf_node_df = pd.DataFrame.from_dict(tf_node_dict,orient='index')\n",
    "tf_rel_node_df = pd.DataFrame.from_dict(tf_rel_node_dict,orient='index')\n",
    "\n",
    "fig,ax1 = plt.subplots()\n",
    "ax1.plot(tf_node_df)\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(tf_rel_node_df.iloc[:2000],color='orange')\n",
    "plt.xticks(range(0,5000,500))\n",
    "plt.axvline(1320, linestyle='dashed', linewidth=1,color='tab:orange')\n",
    "\n",
    "ax1.grid()\n",
    "ax1.margins(x=0.00,y=0)\n",
    "ax2.margins(x=0.00,y=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4cf0b3-42ff-404e-9745-7aaf0ce09378",
   "metadata": {},
   "outputs": [],
   "source": [
    "#max tf 1320\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8809f83d-2390-4661-916b-8cbb7a422af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "seq_net = Network(height='750px', width='100%', bgcolor='#FFFFFF', font_color='black',notebook=True,  directed=True, layout = True) #\n",
    "\n",
    "# set the physics layout of the network\n",
    "#seq_net.barnes_hut()\n",
    "\n",
    "#colorpalette\n",
    "cmap = cm.get_cmap('bwr_r')\n",
    "\n",
    "#shapelist:\n",
    "shapes = ['dot','triangle','square','star']\n",
    "\n",
    "#add nodes\n",
    "for node in rel_nodes:\n",
    "    #determin color by winrate\n",
    "    color = mplt.colors.to_hex(cmap(int(node.winrate*255)))\n",
    "\n",
    "    seq_net.add_node(node.id, color = color,\n",
    "                     label = str(round(node.winrate,2)) + \"_\" + str(node.visits), \n",
    "                     value = node.visits, title = node.id , level = node.level, \n",
    "                     Y= node.winrate*100\n",
    "                     , x = node.winrate*100 , shape = shapes[node.age]) #level=\n",
    "    \n",
    "for node in rel_nodes:\n",
    "    for out_node_id in node.in_edges:\n",
    "        \n",
    "        if out_node_id in rel_node_ids:\n",
    "            out_node = nodes[out_node_id]\n",
    "        \n",
    "            #if node.in_edges[out_node.id] >= out_node.visits*prob_threshold:#edge_threshold:#and abs(round(node.winrate-out_node.winrate,2)) > 0.05 :\n",
    "            seq_net.add_edge(out_node.id, node.id, value=node.in_edges[out_node.id],title=f'Prob: {round(node.in_edges[out_node.id]/out_node.visits,2)} - Use: {node.in_edges[out_node.id]}-  WRD: {round(node.winrate-out_node.winrate,2)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c81b951-183e-4f67-a6d8-42858cc3cc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_net.toggle_physics(False)\n",
    "seq_net.save_graph('lvl_seq_net.html')\n",
    "#seq_net.show('lvl_seq_net.html')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df09964f-b586-42a6-946c-6b46fd95af3c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/niel/.conda/envs/aoeanalytics2/lib/python3.8/site-packages/scipy/spatial/distance.py:630: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "334 Clusters found\r"
     ]
    }
   ],
   "source": [
    "numclust = max_numclust\n",
    "numclust_dist_dict = {}\n",
    "level_node_dict = {}\n",
    "\n",
    "#for numclust in range(max_numclust-1,max_numclust):\n",
    "if True:    \n",
    "    #collect statistics for all numbers of clusters in the range\n",
    "    numclust_dist_dict[numclust] = {}\n",
    "    \n",
    "\n",
    "    level_ub = 0\n",
    "    snapshot_level = 600\n",
    "    cluster_dict = {}\n",
    "    size_limit = 100000000000\n",
    "\n",
    "    #initilize level list und root cluster mit root node\n",
    "    level_list = [0]\n",
    "    cluster_dict[level_ub] = {}\n",
    "    cluster_dict[level_ub][0] = TreeNodeCluster(0,0,[nodes[root_node_id]])\n",
    "    \n",
    "    \n",
    "    while True:\n",
    "        #print_txt(f'Curr Numclust: {numclust} - level_ub: {level_ub}')\n",
    "        level_ub += level_step\n",
    "        level_node_dict[level_ub] = []\n",
    "        \n",
    "        #for each timeframe slice - cluster nodes around mainlines with weighted distance between states distance in higher number is maller than in lower number\n",
    "        node_list = []\n",
    "        ordered_node_list = []\n",
    "        visit_list = []\n",
    "        \n",
    "        #use euclidan distance, avoid join in case of big wr gap, add cost function for \n",
    "\n",
    "\n",
    "        #order select nodes in from tf and order by number of visits\n",
    "        for node in rel_nodes:\n",
    "            if node.level == level_ub:\n",
    "                idx = bisect(visit_list, node.visits)\n",
    "                ordered_node_list.insert(idx,node)\n",
    "                visit_list.insert(idx,node.visits)\n",
    "                level_node_dict[level_ub].append(node)\n",
    "                \n",
    "                \n",
    "        ordered_node_list.reverse()\n",
    "\n",
    "        #if no more rel_nodes break\n",
    "        if len(ordered_node_list) <= 1:\n",
    "            #print_txt(f'No more at tf {curr_tf}')\n",
    "            break\n",
    "        else:\n",
    "            cluster_dict[level_ub] = {}\n",
    "            level_list.append(level_ub)\n",
    "\n",
    "        #enforce size_limit if set\n",
    "        ordered_node_list = ordered_node_list[:size_limit]\n",
    "\n",
    "        x = [node.id for node in ordered_node_list]\n",
    "        y = [node.state_vector.copy() for node in ordered_node_list]\n",
    "        y_norm = norm_vectors(y)\n",
    "        \n",
    "        #create denogram\n",
    "        linkage_data = linkage(y_norm, method='average', metric='cosine')\n",
    "\n",
    "        if level_ub == snapshot_level:\n",
    "            link_exp = linkage_data.copy()\n",
    "            x_exp = x.copy()\n",
    "\n",
    "\n",
    "        cluster_dict[level_ub] = {}\n",
    "        #for clusters and sort into list and create TreeNodeClusters\n",
    "\n",
    "        ##cluster\n",
    "        fcluster_list = fcluster(linkage_data,numclust,criterion='maxclust')\n",
    "        ##read into clusters into list dict\n",
    "        clusters = {}\n",
    "        for idx in range(numclust):\n",
    "            clusters[idx] = []\n",
    "\n",
    "        for idx, i in enumerate(fcluster_list):\n",
    "            clusters[i-1].append(ordered_node_list[idx])\n",
    "\n",
    "        ##convert into TreeNodeCluster and collect distance\n",
    "        total_dist = 0\n",
    "        c = 0\n",
    "        for c_id in clusters:\n",
    "            if len(clusters[c_id]) > 0:\n",
    "                cluster_dict[level_ub][c_id] = TreeNodeCluster(c_id,level_ub,clusters[c_id])\n",
    "                total_dist += cluster_dict[level_ub][c_id].avg_intra_dist\n",
    "                c += 1\n",
    "\n",
    "        #get dist stats\n",
    "        numclust_dist_dict[numclust][level_ub] = total_dist/c\n",
    "        \n",
    "        \n",
    "    #loop over all clusters and add edges and add to global cluster dict do lopp more conveniet and address by id\n",
    "    glob_cluster_dict = {}\n",
    "\n",
    "    for level_ub in level_list:\n",
    "        for c_id in cluster_dict[level_ub]:\n",
    "            cluster_dict[level_ub][c_id].get_cluster_edges()\n",
    "            glob_cluster_dict[cluster_dict[level_ub][c_id].id] = cluster_dict[level_ub][c_id]\n",
    "            #print(cluster_dict[curr_tf][c_id].id,cluster_dict[curr_tf][c_id].out_edges, glob_cluster_dict[cluster_dict[curr_tf][c_id].id].out_edges)\n",
    "\n",
    "print_txt(f'{len(glob_cluster_dict)} Clusters found')\n",
    "output = open('data/tree_rep/lvl_numclust_dist_dict.pkl' , 'wb')\n",
    "pickle.dump(numclust_dist_dict, output)\n",
    "output.close() \n",
    "output = open('data/tree_rep/lvl_level_list.pkl' , 'wb')\n",
    "pickle.dump(level_list, output)\n",
    "output.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d656531-4982-4433-9535-adbeb26ee122",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf_list\n",
    "\n",
    "#tf_list_short = [i for i in range(480,2000,240)]#[600,960,1200,1440,1800]\n",
    "\n",
    "#labels = []\n",
    "#for tf in tf_list_short:\n",
    "#    labels.append(f'TF: {tf} ({len(tf_node_dict[tf])} rem. nodes)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3b0904-dcd4-44d3-acc0-d41572271585",
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot_clusterdist:\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    fig.figsize=(6,6)\n",
    "    ax.set_xlim([2, max_numclust])\n",
    "    ax.set_ylim([0, 0.00004])\n",
    "    plt.xlabel(\"Number of Clusters\",fontsize=14)\n",
    "    plt.ylabel(\"Mean Intra Cluster Distance\",fontsize=14)\n",
    "    plt.grid(color='lightgrey', linestyle='-', linewidth=2)\n",
    "\n",
    "    ax.tick_params(axis='y', which='major', labelsize=14)\n",
    "    ax.tick_params(axis='x', which='major', labelsize=14)\n",
    "    ax.yaxis.offsetText.set_fontsize(14)\n",
    "\n",
    "    #plt.title(f'Avg Intra Cluster Distance per Number of Clusters')\n",
    "\n",
    "    for tf in tf_list_short:#tf_list[1:]:\n",
    "        x = [i for i in range(2,max_numclust)]\n",
    "        y = [numclust_dist_dict[numclust][tf] for numclust in x]\n",
    "        if len(x)>0:\n",
    "            ax.plot(x,y)\n",
    "    #ax = plt.gca()\n",
    "\n",
    "\n",
    "    ax.legend(labels,fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(viz_path +f'Clusterdist_numclust_time.png')\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fd7924-8de2-44d5-927a-32495a1218d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get info about snapshot\n",
    "if False:\n",
    "    curr_tf = snapshot_tf\n",
    "    for c_id in cluster_dict[curr_tf]:\n",
    "        print(cluster_dict[curr_tf][c_id].visits,round(cluster_dict[curr_tf][c_id].winrate,2),cluster_dict[curr_tf][c_id].id,cluster_dict[curr_tf][c_id].avg_intra_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105f903a-c069-4887-91bc-d74b82221f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot Dendogram\n",
    "\n",
    "if False:\n",
    "    figure(figsize=(16, 10), dpi=50)\n",
    "    plt.rcParams.update({'font.size': 22})\n",
    "    dendrogram(link_exp,labels =x_exp, orientation='right')\n",
    "    ax = plt.gca()\n",
    "    ax.tick_params(axis='y', which='major', labelsize=14)\n",
    "    ax.tick_params(axis='x', which='major', labelsize=14)\n",
    "    ax.set_xscale('linear')\n",
    "    ax.set_xlim([0, 0.1])\n",
    "    ax.set_xlabel('Cluster Distance(Cosine Similarity)',fontsize=16)\n",
    "    #ax.set_ylabel('Nodes',fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(viz_path+ f\"Dendogram_tf{snapshot_tf}.png\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcb536c-cdfd-4388-9bb3-cfd857301fa0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "seq_net_clust = Network(height='1440px', width='100%', bgcolor='#FFFFFF', font_color='black',\n",
    "                        notebook=True,  directed=True, layout = True) #\n",
    "\n",
    "# set the physics layout of the network\n",
    "#seq_net.barnes_hut()\n",
    "early_tf = 480\n",
    "weight_threshold = 15000\n",
    "#colorpalette\n",
    "cmap = cm.get_cmap('bwr_r')\n",
    "\n",
    "#shapelist:\n",
    "shapes = ['dot','triangle','square','star','diamond','triangleDown','icon']\n",
    "#shapedict:\n",
    "shape_dict = {'init': 'dot','Age': 'dot','Villager' :'dot', 'Monk':'dot', 'Trade Cart':'dot', \n",
    "              'Infantry':'triangle', 'Foot Archer unit':'square', 'Cavalry':'star', \n",
    "              'Siege unit':'diamond', 'Gunpowder':'triangleDown', 'Ship':'icon', 'Mounted Archer':'square'}\n",
    "global xpos_dict    \n",
    "xpos_dict = {'init': 0,\n",
    " 'Age': 1,\n",
    " 'Villager': 2,\n",
    " 'Monk': 3,\n",
    " 'Trade Cart': 4,\n",
    " 'Infantry': 5,\n",
    " 'Foot Archer unit': 6,\n",
    " 'Cavalry': 7,\n",
    " 'Siege unit': 8,\n",
    " 'Gunpowder': 9,\n",
    " 'Ship': 10,\n",
    " 'Mounted Archer': 11}\n",
    "\n",
    "#add cluster_nodes\n",
    "for clust_id in glob_cluster_dict:\n",
    "        cluster = glob_cluster_dict[clust_id]\n",
    "        #determin color by winrate\n",
    "        color = mplt.colors.to_hex(cmap(int(cluster.winrate*255)))\n",
    "        seq_net_clust.add_node(cluster.id, color = color,\n",
    "                               label = str(round(cluster.winrate,2)) + \"_\" + str(cluster.visits), \n",
    "                               value = cluster.visits, title = cluster.label , \n",
    "                               level = cluster.level, Y= xpos_dict[cluster.dominant_key], \n",
    "                               x = xpos_dict[cluster.dominant_key], shape=shape_dict[cluster.dominant_key]) #level= # shape\n",
    "\n",
    "        \n",
    "for clust_id in glob_cluster_dict:\n",
    "    in_clust = glob_cluster_dict[clust_id]\n",
    "    for out_clust_id in in_clust.in_edges:\n",
    "        out_clust = glob_cluster_dict[out_clust_id]\n",
    "        #print(out_clust_id)\n",
    "        prob = round(in_clust.in_edges[out_clust.id]/out_clust.visits,2)\n",
    "        use = in_clust.in_edges[out_clust.id]\n",
    "        \n",
    "        if use >= weight_threshold:\n",
    "            weight_use = weight_threshold\n",
    "        else: weight_use = use\n",
    "        \n",
    "        if True:#in_clust.in_edges[out_clust.id]/out_clust.visits >= prob_threshold:#in_clust.in_edges[out_clust.id] >= edge_threshold:#and abs(round(node.winrate-out_node.winrate,2)) > 0.05 :\n",
    "            seq_net_clust.add_edge(out_clust.id, in_clust.id, value=weight_use,\n",
    "                                   title=f'Prob: {prob} - Use: {use}-  WRD: {round(in_clust.winrate-out_clust.winrate,2)}')\n",
    "\n",
    "#seq_net_clust.font_size=300\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3a00ca-d2d4-4b28-ac18-030fcaf738a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"1440px\"\n",
       "            src=\"lvl_seq_net_clust.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f9d10e05c70>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_net_clust.toggle_physics(False)\n",
    "seq_net_clust.save_graph('lvl_seq_net_clust.html')\n",
    "seq_net_clust.show('lvl_seq_net_clust.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b4f4e8-2173-413d-9bef-cfad669b6513",
   "metadata": {},
   "outputs": [],
   "source": [
    "#next steps\n",
    "##color encoding of dominant troops\n",
    "##ellbow method for number of clusters make them vary\n",
    "## add vills\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e55c74-6974-46b6-adaf-941bbcacc830",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3d6104-0848-4d32-ac1b-4442a55b469b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aoeanalytics2",
   "language": "python",
   "name": "aoeanalytics2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
