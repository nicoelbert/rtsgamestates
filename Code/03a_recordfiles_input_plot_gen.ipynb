{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "# 03a - Record File Input Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in /home/niel/.conda/envs/aoeanalytics2/lib/python3.8/site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/niel/.conda/envs/aoeanalytics2/lib/python3.8/site-packages (from bs4) (4.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/niel/.conda/envs/aoeanalytics2/lib/python3.8/site-packages (from beautifulsoup4->bs4) (2.3.2.post1)\n",
      "Requirement already satisfied: lxml in /home/niel/.conda/envs/aoeanalytics2/lib/python3.8/site-packages (4.8.0)\n",
      "Requirement already satisfied: psutil in /home/niel/.conda/envs/aoeanalytics2/lib/python3.8/site-packages (5.9.0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install --upgrade pip -q\n",
    "!{sys.executable} -m pip install pandas -q\n",
    "!{sys.executable}  -m pip install numpy -q\n",
    "!{sys.executable}  -m pip install matplotlib -q\n",
    "!{sys.executable}   -m pip install scipy -q\n",
    "!{sys.executable} -m pip install bs4\n",
    "!{sys.executable} -m pip install lxml\n",
    "!{sys.executable} -m pip install psutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#notes:\n",
    "#next params Gather, Order, Research\n",
    "create_posdf = False\n",
    "#todos: calculate how many matches start in not diagonal opposing quadrants -ggf find another way to generalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "OfaaylU24Zb8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "svmem(total=540679213056, available=202066710528, percent=62.6, used=334329839616, free=204628910080, active=19713208320, inactive=305890889728, buffers=42250240, cached=1678213120, shared=259538944, slab=8236654592)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import pickle\n",
    "import numpy.random\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "from datetime import datetime \n",
    "from datetime import timedelta\n",
    "from datetime import time\n",
    "from matplotlib import cm\n",
    "psutil\n",
    "import gc\n",
    "\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (15,15)\n",
    "\n",
    "psutil.virtual_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_txt(msg: str):\n",
    "    #print(msg, end = '\\r')\n",
    "    text_file = open(\"data/scraped_matches/Output_inputplot.txt\", \"w\")\n",
    "    text_file.write(msg)\n",
    "    text_file.close()\n",
    "    \n",
    "def print_txt_global(msg: str):\n",
    "    print(msg)\n",
    "    text_file = open(\"data/scraped_matches/Output_inputplot_global.txt\", \"w\")\n",
    "    text_file.write(msg)\n",
    "    text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "XfOa_fR1cnIJ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "svmem(total=540679213056, available=202056032256, percent=62.6, used=334341013504, free=204618727424, active=19713126400, inactive=305900318720, buffers=42266624, cached=1677205504, shared=259538944, slab=8238338048)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psutil.virtual_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "SIp6oh-Bc5yc"
   },
   "outputs": [],
   "source": [
    "## def functions\n",
    "def get_tile_value(tile_values: dict): \n",
    "    value = 0\n",
    "    \n",
    "    #for now zero for equal values\n",
    "    if tile_values[1] > tile_values[2]:\n",
    "        value = tile_values[1]\n",
    "    elif tile_values[1] < tile_values[2]:\n",
    "        value = -tile_values[2]\n",
    "    \n",
    "    return value\n",
    "\n",
    "def get_result_matrix(control_matrix: list, distance_factor = 0.9, exploration_distance = 10, map_size =121):\n",
    "    \"\"\" Creates a plotable result matrix based on a given control matrix with 3 values per coordinate\"\"\"\n",
    "    #create result matrix\n",
    "    result_matrix = []\n",
    "    \n",
    "    for x in range(map_size):\n",
    "        y_list = []\n",
    "        for y in range(map_size):\n",
    "            y_list.append(get_tile_value(control_matrix[x][y]))\n",
    "        result_matrix.append(y_list)\n",
    "\n",
    "    result_matrix_initial = deepcopy(result_matrix)  \n",
    "    \n",
    "    moves = [i for i in range(-exploration_distance,exploration_distance+1)]\n",
    "    \n",
    "    \n",
    "    #calculate values for tiles around \n",
    "    if False:\n",
    "        for x in range(map_size):\n",
    "            for y in range(map_size):\n",
    "                if result_matrix_initial[x][y] == 0:\n",
    "                    val_sum = 0\n",
    "                    val_count = 0\n",
    "\n",
    "                    for x_move in moves:\n",
    "                        for y_move in moves:\n",
    "                            try:\n",
    "                                distance = abs(x_move) + abs(y_move)\n",
    "                                diff = (result_matrix_initial[x + x_move][y + y_move] * pow(distance_factor,distance))\n",
    "\n",
    "                                if diff != 0:\n",
    "                                    val_count += 1\n",
    "                                    val_sum += diff\n",
    "                            except: \n",
    "                                pass \n",
    "\n",
    "                    try:\n",
    "                        #print(result_matrix_initial[x][y])\n",
    "                        result_matrix[x][y] = val_sum/val_count\n",
    "                        #print(result_matrix_initial[x][y])\n",
    "\n",
    "                    except:\n",
    "                        pass\n",
    "                    \n",
    "            \n",
    "    return result_matrix\n",
    "\n",
    "\n",
    "\n",
    "def add_minutes(old_time: datetime.time, minutes: int):\n",
    "    \"\"\" adds minutes to a given datetime.time\"\"\"\n",
    "    hour = old_time.hour\n",
    "    minute = old_time.minute\n",
    "    second = old_time.second\n",
    "    \n",
    "    minute += minutes\n",
    "    \n",
    "    if minute >= 60:\n",
    "        minute -= 60\n",
    "        hour += 1\n",
    "    \n",
    "    t_new = time(hour = hour, minute = minute, second = second)\n",
    "    return t_new\n",
    "\n",
    "def create_control_matrix(view: pd.DataFrame, inf_dist = 5, map_size = 121):\n",
    "    \"\"\" return mapcontrol matrix from view\"\"\" \n",
    "    control_matrix = {}\n",
    "    #first round add together all values on tiles\n",
    "    #create inital matrix with values for 0 control \n",
    "    for x in range(map_size):\n",
    "        control_matrix[x]= {}\n",
    "        for y in range(map_size):\n",
    "            control_matrix[x][y] = {0: 0, 1: 0, 2: 0}\n",
    "            \n",
    "\n",
    "\n",
    "    #fill with number of actions on that given spot\n",
    "    for index, action in view.iterrows():\n",
    "        control_matrix[int(action['x_pos'])][int(action['y_pos'])][action['acting_player']] += 1\n",
    "\n",
    "\n",
    "    #approach 1 normalize -> approach 2 would be to keep values in relation\n",
    "    for x in range(map_size):\n",
    "        for y in range(map_size):\n",
    "            val_count = 0\n",
    "            #count total values\n",
    "            for index in control_matrix[x][y]:\n",
    "                val_count += control_matrix[x][y][index]\n",
    "            if False:\n",
    "                #now normalize\n",
    "                if val_count > 0:\n",
    "                    for index in control_matrix[x][y]:\n",
    "                        control_matrix[x][y][index] = control_matrix[x][y][index]/val_count\n",
    "    return control_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6QUWHqxrf99J",
    "outputId": "cdd717a5-9071-4208-da70-e60b7482af0d"
   },
   "outputs": [],
   "source": [
    "def create_plot_from_df(matches_df):\n",
    "    import psutil\n",
    "    temp_memory_dev = []\n",
    "    \n",
    "    #convert df into dict\n",
    "    matches = matches_df.set_index('match_id').to_dict(\"index\")\n",
    "\n",
    "    ############################## read data from inputs ##############################\n",
    "    error_count = 0\n",
    "    tb_del = []\n",
    "    \n",
    "    #load pkl files\n",
    "    for index, match in enumerate(matches):\n",
    "        try:\n",
    "            with open(matches[match]['input_fn'], 'rb') as f:\n",
    "                matches[match]['inputs'] = pickle.load(f)\n",
    "        except:\n",
    "            error_count += 1\n",
    "            tb_del.append(match)\n",
    "\n",
    "        if index % 100 == 0:\n",
    "            print(\"Imported \", index, \" / \", len(matches), \" - error on :\", error_count,  end='\\r')\n",
    "\n",
    "    for match in tb_del:\n",
    "      del matches[match]\n",
    "    \n",
    "    #gc.collect()\n",
    "    print(\"Deleted: \",len(tb_del), \" - Remaining: \", len(matches))\n",
    "    \n",
    "\n",
    "    ############################## create posdf ##############################\n",
    "\n",
    "    #read in input data from matplotlib import cm\n",
    "    count = 0\n",
    "    pos_inputs = {}\n",
    "    types = {}\n",
    "    \n",
    "    for index, match in enumerate(matches):\n",
    "        \n",
    "        #create single dict per match\n",
    "        with open(matches[match]['input_fn'], 'rb') as f:\n",
    "                matches[match]['inputs'] = pickle.load(f)\n",
    "        \n",
    "        for input in matches[match]['inputs']:\n",
    "            #determine acting player\n",
    "            if matches[match]['inputs'][input]['player'] ==  'p1':\n",
    "                acting_player = 1#matches[match]['p1_name']\n",
    "            elif matches[match]['inputs'][input]['player'] ==  'p2':\n",
    "                acting_player = 2#matches[match]['p2_name']\n",
    "            else: acting_player = 0\n",
    "\n",
    "            ##obsolete\n",
    "            #print(acting_player, matches[match]['inputs'][input]['x_pos'])\n",
    "            this_type = matches[match]['inputs'][input]['type']\n",
    "\n",
    "            if this_type not in types:\n",
    "                types[this_type] = 0\n",
    "            else:\n",
    "                types[this_type] += 1\n",
    "\n",
    "            #only read posistion and player related inputs\n",
    "            if matches[match]['inputs'][input]['x_pos'] != None and acting_player != 0:\n",
    "                count += 1\n",
    "                row_id = str(match)+\"-\"+str(input)\n",
    "                pos_inputs[row_id] = {}\n",
    "                pos_inputs[row_id]['match_id'] = match\n",
    "                pos_inputs[row_id]['move_id'] = input\n",
    "\n",
    "                #enrich time data\n",
    "                try:\n",
    "                    pos_inputs[row_id]['time'] = datetime.strptime(matches[match]['inputs'][input]['timestamp'],'%H:%M:%S.%f').time()\n",
    "                except:\n",
    "                    pos_inputs[row_id]['time'] = datetime.strptime(matches[match]['inputs'][input]['timestamp'],'%H:%M:%S').time()\n",
    "\n",
    "                #read player data\n",
    "                pos_inputs[row_id]['acting_player'] = acting_player\n",
    "\n",
    "                #read redundant data from matches into every row: \n",
    "                for key in matches[match].keys():\n",
    "                    pos_inputs[row_id][key] = matches[match][key]\n",
    "\n",
    "                #add move data\n",
    "                for key in matches[match]['inputs'][input]:\n",
    "                    pos_inputs[row_id][key] = matches[match]['inputs'][input][key]\n",
    "        \n",
    "        #clear memory\n",
    "        del matches[match]['inputs']\n",
    "        \n",
    "        if index % 1000 == 0:\n",
    "            temp_pos_inputs_df = pd.DataFrame.from_dict(pos_inputs,orient=\"index\")\n",
    "\n",
    "            if index > 1000:\n",
    "                    pos_inputs_df = pd.concat([pos_inputs_df, temp_pos_inputs_df])\n",
    "            else:\n",
    "                #first run\n",
    "                pos_inputs_df = temp_pos_inputs_df\n",
    "\n",
    "            print_txt(f'Concat after {index} matches - currently {pos_inputs_df.shape}')\n",
    "\n",
    "            #reset pos inputs\n",
    "            pos_inputs = {}\n",
    "            gc.collect()\n",
    "        \n",
    "        \n",
    "\n",
    "        print(\"Read Data from Match  \", index, \" / \", len(matches),  end='\\r')\n",
    "\n",
    "    print(\"Read Data from Match  \", index, \" / \", len(matches))\n",
    "    print(\"Found \", len(pos_inputs), \" Inputs\")\n",
    "    print(\"Start creating df from dict\")\n",
    "\n",
    "    #final append\n",
    "    temp_pos_inputs_df = pd.DataFrame.from_dict(pos_inputs,orient=\"index\")               \n",
    "    pos_inputs_df = pd.concat([pos_inputs_df, temp_pos_inputs_df])\n",
    "\n",
    "\n",
    "    #final persistation\n",
    "    output = open('data/scraped_matches/pos_inputs_df.pkl' , 'wb')\n",
    "    pickle.dump(pos_inputs_df, output)\n",
    "    output.close()\n",
    "\n",
    "    print_txt(f'Concat after {len(matches)} matches - currentetly {pos_inputs_df.shape}')\n",
    "    print(types)\n",
    "\n",
    "\n",
    "    print(f'Shape pos_df: {pos_inputs_df.shape}, memory: {str(psutil.virtual_memory()[2])} %')\n",
    "\n",
    "    ############################## create plots ##############################\n",
    "    dir_path = 'data/minn/unfoldered_layers/'\n",
    "    actions = [\"Build\",\"Target\",\"Move\"]\n",
    "    map_size = 121\n",
    "    errors = 0\n",
    "    error_list = []\n",
    "\n",
    "    import psutil\n",
    "    psutil.virtual_memory()\n",
    "\n",
    "    for counter, match in enumerate(matches):\n",
    "\n",
    "        try:\n",
    "            pos_inputs_match_df = pos_inputs_df[pos_inputs_df['match_id'] == match]\n",
    "            #create views for the different actions\n",
    "            df_views = {}\n",
    "            views = []\n",
    "            for action in actions:\n",
    "                df_views[action] = pos_inputs_match_df[pos_inputs_match_df['type'] == action]\n",
    "                df_views[action].name = action\n",
    "                views.append(df_views[action])\n",
    "\n",
    "            #create plots for the different views\n",
    "            for view in views:\n",
    "                #get matrix\n",
    "                result_matrix = get_result_matrix(create_control_matrix(view, map_size = map_size),map_size = map_size)\n",
    "                #plot\n",
    "                figure, axes = plt.subplots()\n",
    "\n",
    "\n",
    "                axes.pcolormesh(result_matrix, cmap='RdYlGn', vmin=-1, vmax=1)\n",
    "\n",
    "                plt.pcolormesh(result_matrix, cmap='RdYlGn', vmin=-1, vmax=1)\n",
    "                plt.axis([0,map_size,0,map_size])\n",
    "\n",
    "                file_path = dir_path + str(match) +'_'+ view.name +'_layer.png'\n",
    "\n",
    "                #correct format\n",
    "                axes.set_axis_off()\n",
    "                figure.set_size_inches(12, 12)\n",
    "\n",
    "                plt.savefig(file_path,dpi = 10)\n",
    "                plt.close(figure)\n",
    "                \n",
    "                del result_matrix\n",
    "                del figure\n",
    "                del axes\n",
    "                \n",
    "                #plt.show()\n",
    "                #plt.rcParams[\"figure.figsize\"] = (15,15)\n",
    "\n",
    "\n",
    "            #delete pos inputs for match\n",
    "            pos_inputs_df = pos_inputs_df[pos_inputs_df['match_id'] != match]\n",
    "            del pos_inputs_match_df\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            errors +=1\n",
    "            error_list.append(match)\n",
    "        \n",
    "        \n",
    "        msg = f'Saved {counter+1}/{len(matches)} matches - last one was: {match} - error on: {errors} - memory: {str(psutil.virtual_memory()[2])} %'\n",
    "        print(msg, end='\\r')\n",
    "\n",
    "        if counter % 100 == 0:\n",
    "            temp_memory_dev.append(' ' + str(psutil.virtual_memory()[2]) + '%')\n",
    "            print_txt(msg + str(temp_memory_dev))\n",
    "        \n",
    "        \n",
    "    ############################## del everything ##############################\n",
    "    del matches\n",
    "    del pos_inputs_df\n",
    "    del temp_pos_inputs_df\n",
    "    del df_views\n",
    "    del views\n",
    "    del output\n",
    "    gc.collect()\n",
    "    #del matches_df\n",
    "    #for view in views:\n",
    "        #del view\n",
    "    #del pos_inputs_df\n",
    "    #del pos_inputs_match_df\n",
    "    #del temp_pos_inputs_df\n",
    "    #gc.collect()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-9204aad189b1>:2: DtypeWarning: Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  matches_df = pd.read_csv('data/scraped_recordfile_matches.csv')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match_id</th>\n",
       "      <th>recordfile</th>\n",
       "      <th>input_fn</th>\n",
       "      <th>map</th>\n",
       "      <th>map_size</th>\n",
       "      <th>duration</th>\n",
       "      <th>p1_name</th>\n",
       "      <th>p2_name</th>\n",
       "      <th>p1_civ</th>\n",
       "      <th>p2_civ</th>\n",
       "      <th>p1_xpos</th>\n",
       "      <th>p2_xpos</th>\n",
       "      <th>p1_ypos</th>\n",
       "      <th>p2_ypos</th>\n",
       "      <th>winner</th>\n",
       "      <th>gaia_fn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>87925986</td>\n",
       "      <td>AgeIIDE_Replay_87925986.aoe2record</td>\n",
       "      <td>data/scraped_matches/inputs/87925986.pkl</td>\n",
       "      <td>Serengeti</td>\n",
       "      <td>Tiny</td>\n",
       "      <td>3003</td>\n",
       "      <td>48mb</td>\n",
       "      <td>Sat Thien Mach</td>\n",
       "      <td>Incas</td>\n",
       "      <td>Vikings</td>\n",
       "      <td>84.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>109059887</td>\n",
       "      <td>AgeIIDE_Replay_109059887.aoe2record</td>\n",
       "      <td>data/scraped_matches/inputs/109059887.pkl</td>\n",
       "      <td>Arabia</td>\n",
       "      <td>Tiny</td>\n",
       "      <td>3472</td>\n",
       "      <td>Ralf</td>\n",
       "      <td>StormX</td>\n",
       "      <td>Berbers</td>\n",
       "      <td>Lithuanians</td>\n",
       "      <td>92.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>132137828</td>\n",
       "      <td>AgeIIDE_Replay_132137828.aoe2record</td>\n",
       "      <td>data/scraped_matches/inputs/132137828.pkl</td>\n",
       "      <td>Arabia</td>\n",
       "      <td>Tiny</td>\n",
       "      <td>746</td>\n",
       "      <td>SaulGoodman</td>\n",
       "      <td>[Tkilla] I'm A.I.</td>\n",
       "      <td>Franks</td>\n",
       "      <td>Mongols</td>\n",
       "      <td>44.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63169375</td>\n",
       "      <td>AgeIIDE_Replay_63169375.aoe2record</td>\n",
       "      <td>data/scraped_matches/inputs/63169375.pkl</td>\n",
       "      <td>Arabia</td>\n",
       "      <td>Tiny</td>\n",
       "      <td>1866</td>\n",
       "      <td>Oblivious White Eel</td>\n",
       "      <td>Shotgun Roddy</td>\n",
       "      <td>Ethiopians</td>\n",
       "      <td>Koreans</td>\n",
       "      <td>20.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>77688193</td>\n",
       "      <td>AgeIIDE_Replay_77688193.aoe2record</td>\n",
       "      <td>data/scraped_matches/inputs/77688193.pkl</td>\n",
       "      <td>Arabia</td>\n",
       "      <td>Tiny</td>\n",
       "      <td>5036</td>\n",
       "      <td>Sinede</td>\n",
       "      <td>TheEskimo</td>\n",
       "      <td>Vietnamese</td>\n",
       "      <td>Malay</td>\n",
       "      <td>44.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    match_id                           recordfile  \\\n",
       "0   87925986   AgeIIDE_Replay_87925986.aoe2record   \n",
       "1  109059887  AgeIIDE_Replay_109059887.aoe2record   \n",
       "2  132137828  AgeIIDE_Replay_132137828.aoe2record   \n",
       "3   63169375   AgeIIDE_Replay_63169375.aoe2record   \n",
       "4   77688193   AgeIIDE_Replay_77688193.aoe2record   \n",
       "\n",
       "                                    input_fn        map map_size  duration  \\\n",
       "0   data/scraped_matches/inputs/87925986.pkl  Serengeti     Tiny      3003   \n",
       "1  data/scraped_matches/inputs/109059887.pkl     Arabia     Tiny      3472   \n",
       "2  data/scraped_matches/inputs/132137828.pkl     Arabia     Tiny       746   \n",
       "3   data/scraped_matches/inputs/63169375.pkl     Arabia     Tiny      1866   \n",
       "4   data/scraped_matches/inputs/77688193.pkl     Arabia     Tiny      5036   \n",
       "\n",
       "               p1_name            p2_name      p1_civ       p2_civ  p1_xpos  \\\n",
       "0                 48mb     Sat Thien Mach       Incas      Vikings     84.0   \n",
       "1                 Ralf             StormX     Berbers  Lithuanians     92.0   \n",
       "2          SaulGoodman  [Tkilla] I'm A.I.      Franks      Mongols     44.0   \n",
       "3  Oblivious White Eel      Shotgun Roddy  Ethiopians      Koreans     20.0   \n",
       "4               Sinede          TheEskimo  Vietnamese        Malay     44.0   \n",
       "\n",
       "   p2_xpos  p1_ypos  p2_ypos  winner gaia_fn  \n",
       "0     23.0     98.0     31.0       0     NaN  \n",
       "1     22.0     83.0     75.0       1     NaN  \n",
       "2     62.0     21.0     99.0       1     NaN  \n",
       "3     98.0     62.0     51.0       1     NaN  \n",
       "4     50.0     96.0     21.0       0     NaN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load matches\n",
    "matches_df = pd.read_csv('data/scraped_recordfile_matches.csv')\n",
    "matches_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nplotted_matches = []\\n\\nfor file in os.listdir(zip_path):\\n    filename = os.fsdecode(file)\\n\\n    match_id = filename.partition(\"=\")[2].partition(\"&\")[0]\\n    scraped_matches.append(match_id)\\n    \\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find already scraped matches for parallel download\n",
    "\"\"\"\n",
    "plotted_matches = []\n",
    "\n",
    "for file in os.listdir(zip_path):\n",
    "    filename = os.fsdecode(file)\n",
    "\n",
    "    match_id = filename.partition(\"=\")[2].partition(\"&\")[0]\n",
    "    scraped_matches.append(match_id)\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 2000\n",
    "total = matches_df.shape[0]\n",
    "position = 74000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting matches 74000 - 76000 of 80104 matches - Memory: 62.6 % -Dev: [' 62.6%']\n",
      "Deleted:  0  - Remaining:  2000r on : 0\n",
      "Read Data from Match   273  /  2000 2000\r"
     ]
    }
   ],
   "source": [
    "memory_dev = []\n",
    "\n",
    "while position < total:\n",
    "    #create temp_df\n",
    "    temp_matches_df = matches_df[matches_df.index < position + size]\n",
    "    temp_matches_df = temp_matches_df[temp_matches_df.index >= position] \n",
    "    \n",
    "    memory_dev.append(' ' + str(psutil.virtual_memory()[2]) + '%')\n",
    "    print_txt_global(f'Plotting matches {position} - {position + size} of {total} matches - Memory: {psutil.virtual_memory()[2]} % -Dev: {memory_dev}')\n",
    "    create_plot_from_df(temp_matches_df)\n",
    "    gc.collect()\n",
    "    \n",
    "    position += size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPZXm1/GeYwAv+MsIAMN1So",
   "include_colab_link": true,
   "name": "aoe2net_aoe2insights_joint_analytics.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "aoeanalytics2",
   "language": "python",
   "name": "aoeanalytics2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
