{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41c63f83",
   "metadata": {
    "id": "41c63f83"
   },
   "source": [
    "# 01 - Recordfile Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "hMYuIGFLTxvN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hMYuIGFLTxvN",
    "outputId": "52c68183-f584-40d4-9bbb-4b777b46feaf"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install --upgrade pip -q\n",
    "!{sys.executable} -m pip install pandas -q\n",
    "!{sys.executable}  -m pip install numpy -q\n",
    "!{sys.executable}  -m pip install matplotlib -q\n",
    "!{sys.executable} -m pip install mgz -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "qFeZYiXBUMRz",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qFeZYiXBUMRz",
    "outputId": "1025d2db-44e4-4dc7-b091-01727f039438"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/niel\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d294dfd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "id": "6d294dfd",
    "outputId": "0d9e7486-ca36-40cb-bf40-beae2ee6e551"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from mgz import header, body\n",
    "from mgz.model import parse_match\n",
    "import pickle\n",
    "import os\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6337c8b4-4f0f-4b2c-8bf3-264f4f07c924",
   "metadata": {},
   "outputs": [],
   "source": [
    "#settings\n",
    "from_pkl = False\n",
    "from_directory = True\n",
    "\n",
    "base_directory = \"aoe_data/data/scraped_matches/\"\n",
    "recordfile_path = base_directory +\"unzipped_recordfiles/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "581812a3-4bc2-4b72-9f3e-695956e63bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if from_pkl:\n",
    "    #load match list from pkl\n",
    "    with open('aoe_data/data/aoe2insights_20k_matchlist.pkl', 'rb') as f:\n",
    "        match_list = pickle.load(f)\n",
    "\n",
    "    match_list = match_list.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45bb8d4a-bd48-4f24-b018-9632dab985e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found  12349  files.\n",
      "12349  Matchfiles found\n"
     ]
    }
   ],
   "source": [
    "if from_directory:\n",
    "    \n",
    "    match_list = []\n",
    "    #unzip all files\n",
    "    directory = os.fsencode(recordfile_path)\n",
    "\n",
    "    files = len(os.listdir(directory))\n",
    "    print(\"Found \",files, \" files.\")\n",
    "    \n",
    "    \n",
    "    for file in os.listdir(directory):\n",
    "        filename = os.fsdecode(file)\n",
    "        match_id = filename[15:-11]\n",
    "        match_list.append(match_id)\n",
    "        \n",
    "print(len(match_list), \" Matchfiles found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc2618f",
   "metadata": {
    "id": "6dc2618f"
   },
   "source": [
    "**Data Preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "RgGUIlouzVbR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RgGUIlouzVbR",
    "outputId": "2df1f5d9-4b10-4f7f-8883-9f3b2d738dd1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12349\n",
      "AgeIIDE_Replay_155650737.aoe2record\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "#prepare files\n",
    "directory = os.fsencode(recordfile_path)\n",
    "filenames = []\n",
    "\n",
    "#get all file names\n",
    "for file in os.listdir(directory):\n",
    "  filename = os.fsdecode(file)\n",
    "  filenames.append(filename)\n",
    "\n",
    "print(len(filenames))\n",
    "print(filenames[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5568cd15",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5568cd15",
    "outputId": "363a4ba8-1f19-4d23-b9b3-0610d8cd3e4e"
   },
   "outputs": [],
   "source": [
    "matches = {}\n",
    "error_count = 0\n",
    "\n",
    "for match_id in match_list:\n",
    "  if error_count >= 1000:\n",
    "    break\n",
    "\n",
    "  filename = 'AgeIIDE_Replay_{}.aoe2record'.format(match_id)\n",
    "\n",
    "  if filename in filenames:\n",
    "    #create dict for each match\n",
    "    matches[match_id] = {}\n",
    "    matches[match_id]['match_id'] = match_id\n",
    "    matches[match_id]['recordfile'] = filename\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "k5HW5FR-XhrS",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k5HW5FR-XhrS",
    "outputId": "ec82f91c-9488-47b2-a997-eed32653635b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed: 5936 - error on:  3179\r"
     ]
    }
   ],
   "source": [
    "#read in data from record files\n",
    "\n",
    "##directorys\n",
    "recordfile_path = recordfile_path\n",
    "input_path = 'aoe_data/data/scraped_matches/inputs/'\n",
    "gaia_path = 'aoe_data/data/scraped_matches/gaia_data/'\n",
    "\n",
    "## orga vars\n",
    "error_count = 0\n",
    "parsed_files = 0\n",
    "to_be_deleted = []\n",
    "input_dict = {}\n",
    "gaia_dict = {}\n",
    "\n",
    "## content vars for feature creation\n",
    "masterdata_dict = {}\n",
    "masterdata_dict['Build'] = []\n",
    "masterdata_dict['Queue'] = []\n",
    "masterdata_dict['Research'] = []\n",
    "\n",
    "##set to True if recreation of record files needed\n",
    "parse_recordfiles = True\n",
    "\n",
    "for match_index,match_id in enumerate(matches):\n",
    "    try:\n",
    "        filepath = recordfile_path + matches[match_id]['recordfile']\n",
    "        matches[match_id]['input_fn'] = input_path + str(match_id) + \".pkl\"\n",
    "        \n",
    "        if parse_recordfiles:\n",
    "\n",
    "            #parse match data\n",
    "            with open(filepath, 'rb') as data:\n",
    "                eof = os.fstat(data.fileno()).st_size\n",
    "                body.meta.parse_stream(data)\n",
    "                while data.tell() < eof:\n",
    "                    body.operation.parse_stream(data)\n",
    "\n",
    "            with open(filepath, 'rb') as data:\n",
    "                match = parse_match(data)\n",
    "                \n",
    "            #get general game info  \n",
    "            matches[match_id]['map'] = match.map.name\n",
    "            matches[match_id]['map_size'] = match.map.size\n",
    "            matches[match_id]['duration'] = match.duration.seconds\n",
    "\n",
    "            #gather player information\n",
    "            players = match.players\n",
    "            matches[match_id]['p1_name'] = players[0].name\n",
    "            matches[match_id]['p2_name'] = players[1].name\n",
    "\n",
    "            matches[match_id]['p1_civ'] = players[0].civilization\n",
    "            matches[match_id]['p2_civ'] = players[1].civilization\n",
    "\n",
    "            matches[match_id]['p1_xpos'] = players[0].position.x\n",
    "            matches[match_id]['p2_xpos'] = players[1].position.x\n",
    "            matches[match_id]['p1_ypos'] = players[0].position.y\n",
    "            matches[match_id]['p2_ypos'] = players[1].position.y\n",
    "\n",
    "\n",
    "            if players[0].winner == True:\n",
    "                matches[match_id]['winner'] = int(0)\n",
    "            else:\n",
    "                matches[match_id]['winner'] = int(1)\n",
    "\n",
    "\n",
    "            #get all item names\n",
    "            for object in match.inputs:\n",
    "                attr_list = object.__dict__.keys()\n",
    "                break\n",
    "\n",
    "            if not str(getattr(object,'type')) == \"Chat\":\n",
    "                inputs_objects_dict = {}\n",
    "\n",
    "            for index, object in enumerate(match.inputs):\n",
    "                inputs_objects_dict[index] = {}\n",
    "\n",
    "                #create timestamp_seconds\n",
    "                inputs_objects_dict[index]['ts_seconds'] = getattr(object,'timestamp').seconds\n",
    "\n",
    "                for attribute in attr_list:\n",
    "                    inputs_objects_dict[index][attribute] = str(getattr(object,attribute))\n",
    "\n",
    "\n",
    "                    #create a list of Builds\n",
    "                    if str(getattr(object,'type')) == 'Build':\n",
    "                        val = str(getattr(object,'param'))\n",
    "                        if val not in masterdata_dict['Build'] :\n",
    "                            masterdata_dict['Build'] .append(val)\n",
    "\n",
    "                    #create list of possible Units\n",
    "                    if str(getattr(object,'type')) == 'Queue':\n",
    "                        val = str(getattr(object,'param'))\n",
    "                        if val not in masterdata_dict['Queue'] :\n",
    "                            masterdata_dict['Queue'] .append(val)\n",
    "\n",
    "                    #create list of Technologies\n",
    "                    if str(getattr(object,'type')) == 'Research':\n",
    "                        val = str(getattr(object,'param'))\n",
    "                        if val not in masterdata_dict['Research'] :\n",
    "                            masterdata_dict['Research'].append(val)\n",
    "\n",
    "\n",
    "                    #create redundant single xy coordinates\n",
    "                    if attribute == 'position':\n",
    "                        pos = getattr(object,attribute)\n",
    "\n",
    "                        if pos == None:\n",
    "                            inputs_objects_dict[index]['x_pos']= None\n",
    "                            inputs_objects_dict[index]['y_pos'] = None \n",
    "                        else:\n",
    "                            inputs_objects_dict[index][\"x_pos\"] = getattr(object,attribute).x\n",
    "                            inputs_objects_dict[index][\"y_pos\"] = getattr(object,attribute).y\n",
    "\n",
    "                    #replace playerinfo\n",
    "                    if attribute == 'player':\n",
    "                        if inputs_objects_dict[index][attribute] == matches[match_id]['p1_name']:\n",
    "                            inputs_objects_dict[index][attribute] = 'p1'\n",
    "                        else:\n",
    "                            inputs_objects_dict[index][attribute] = 'p2'\n",
    "\n",
    "\n",
    "            #read gaia data\n",
    "            gaia_objects_dict = {}\n",
    "            for object in match.gaia:\n",
    "                if getattr(object,\"name\"):\n",
    "                    #read gaia data in\n",
    "                    gaia_objects_dict[object.instance_id] = {}\n",
    "                    gaia_objects_dict[object.instance_id][\"name\"] = getattr(object,\"name\")\n",
    "                    gaia_objects_dict[object.instance_id][\"x_pos\"] = getattr(object,'position').x\n",
    "                    gaia_objects_dict[object.instance_id][\"y_pos\"] = getattr(object,'position').y\n",
    "\n",
    "            #write dicts into global dict\n",
    "            input_dict[match_id] = inputs_objects_dict\n",
    "            gaia_dict[match_id] = gaia_objects_dict\n",
    "\n",
    "            #persistate inputs in pkl file\n",
    "            matches[match_id]['input_fn'] = input_path + str(match_id) + \".pkl\"\n",
    "            output = open(matches[match_id]['input_fn'] , 'wb')\n",
    "            pickle.dump(inputs_objects_dict, output)\n",
    "            output.close()\n",
    "\n",
    "            #persitate gaia_data\n",
    "            matches[match_id]['gaia_fn'] = gaia_path + str(match_id) + \".pkl\"\n",
    "            output = open(matches[match_id]['gaia_fn'] , 'wb')\n",
    "            pickle.dump(gaia_objects_dict, output)\n",
    "            output.close()\n",
    "\n",
    "\n",
    "            if index % 1000 == 0:\n",
    "                #persistate inputs in pkl file\n",
    "                matches[match_id]['input_fn'] = directory + \"inputs/over_time/\" + str(match_id) + \"_\" + str(index) + \".pkl\"\n",
    "                output = open(matches[match_id]['input_fn'] , 'wb')\n",
    "                pickle.dump(inputs_objects_dict, output)\n",
    "                output.close()\n",
    "\n",
    "                #persitate gaia_data\n",
    "                matches[match_id]['gaia_fn'] = directory + \"gaia_data/over_time/\" + str(match_id) + \"_\" + str(index) + \".pkl\"\n",
    "                output = open(matches[match_id]['gaia_fn'] , 'wb')\n",
    "                pickle.dump(gaia_objects_dict, output)\n",
    "                output.close()\n",
    "\n",
    "                #persitate matches\n",
    "                file_name = directory + \"parsed_matches/over_time/\" + \"_\" + str(index) + \".pkl\"\n",
    "                output = open(file_name, 'wb')\n",
    "                pickle.dump(matches, output)\n",
    "                output.close()\n",
    "\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        #print(match_id, filepath)\n",
    "        #print(e, \"Match_id:\", match_id)\n",
    "        to_be_deleted.append(match_id)\n",
    "        error_count +=1\n",
    "        if error_count >= 100:\n",
    "          pass#break\n",
    "        pass\n",
    "\n",
    "    if parse_recordfiles:\n",
    "        parsed_files += 1\n",
    "        print(\"Parsed:\" , parsed_files, \"- error on: \", error_count,  end='\\r')\n",
    "\n",
    "#errorhandling\n",
    "print(\"Parsed:\" , parsed_files, \"- error on: \", error_count)\n",
    "print(\"Deleting: \", to_be_deleted)\n",
    "for match_id in to_be_deleted:\n",
    "    del matches[match_id]\n",
    "\n",
    "if parse_recordfiles:\n",
    "    #presistate full input dict\n",
    "    full_fn = input_path + 'all_inputs.pkl'\n",
    "    output = open(full_fn , 'wb')\n",
    "    pickle.dump(input_dict, output)\n",
    "    output.close()\n",
    "\n",
    "    print(\"Error on \",error_count,\" matches while parsing recordfile data\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f9c58a-0786-490a-9967-c63738f6fc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#persitate matches\n",
    "file_name = 'aoe_data/data/scraped_matches/parsed_matches/final_matches.pkl'\n",
    "output = open(file_name, 'wb')\n",
    "pickle.dump(matches, output)\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c14462d-67e9-481e-807a-cdff27b3fb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fNc8HtNXdbA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 270
    },
    "id": "2fNc8HtNXdbA",
    "outputId": "dde11112-f578-4ad0-ca45-2988e946aebd"
   },
   "outputs": [],
   "source": [
    "matches_df = pd.DataFrame.from_dict(matches, orient='index')\n",
    "\n",
    "matches_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7973106",
   "metadata": {
    "id": "f7973106"
   },
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0bfec8-d348-47e7-88a0-36c39e782828",
   "metadata": {},
   "outputs": [],
   "source": [
    "#manual add masterdata\n",
    "masterdata_dict['Ages'] = ['Feudal Age','Castle Age','Imperial Age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d25f43-35c7-4486-8f34-6749212a5bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in masterdata_dict:\n",
    "    print(key, \": \",len(masterdata_dict[key]))\n",
    "\n",
    "#persistate master data\n",
    "masterdata_path = 'aoe_data/masterdata/'\n",
    "\n",
    "output = open(masterdata_path + 'masterdata_dict.pkl' , 'wb')\n",
    "pickle.dump(masterdata_dict, output)\n",
    "output.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fb97e9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c5fb97e9",
    "outputId": "955bd374-4b6a-48ea-d42e-87c5ceadd559"
   },
   "outputs": [],
   "source": [
    "matches_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_mmOB2yoXQbE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_mmOB2yoXQbE",
    "outputId": "fa51c3ad-3665-4449-f70f-b2457f9f9c38"
   },
   "outputs": [],
   "source": [
    "matches_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NlV66I8jXFKD",
   "metadata": {
    "id": "NlV66I8jXFKD"
   },
   "outputs": [],
   "source": [
    "#write preprocessed matches_df into csv\n",
    "matches_df.to_csv('aoe_data/data/scraped_recordfile_matches.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "obujrDrPcSaO",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 270
    },
    "id": "obujrDrPcSaO",
    "outputId": "b93263a2-4f7f-46b5-c176-5dce98720557"
   },
   "outputs": [],
   "source": [
    "matches_df = pd.read_csv('aoe_data/data/scraped_recordfile_matches.csv')\n",
    "matches_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9a0b9c-b348-4e38-961f-9db2a58d14b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_df.groupby(['map']).size().reset_index(name='counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad43f214-79be-4693-a4c0-d2df3d820bad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "win_prob_calculation-checkpoint.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "aoeanalytics2",
   "language": "python",
   "name": "aoeanalytics2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
